name: AJD Topic Explorer CI

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  lint-and-validate:
    name: Lint & CSV validation
    runs-on: ubuntu-latest
    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies (project + lint)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install flake8

      - name: Rebuild merged CSVs from chunked parts
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data

          # Merge topics (parts 01..12)
          if ls data/ajd_topics_extracted.part*.csv 1> /dev/null 2>&1; then
            head -n 1 data/ajd_topics_extracted.part01.csv > data/ajd_topics_extracted.csv
            for f in data/ajd_topics_extracted.part*.csv; do
              if [[ "$f" != "data/ajd_topics_extracted.part01.csv" ]]; then
                tail -n +2 "$f" >> data/ajd_topics_extracted.csv
              fi
            done
          fi

          # Merge catalogue (parts 01..07)
          if ls data/ajd_catalogue_raw.part*.csv 1> /dev/null 2>&1; then
            head -n 1 data/ajd_catalogue_raw.part01.csv > data/ajd_catalogue_raw.csv
            for f in data/ajd_catalogue_raw.part*.csv; do
              if [[ "$f" != "data/ajd_catalogue_raw.part01.csv" ]]; then
                tail -n +2 "$f" >> data/ajd_catalogue_raw.csv
              fi
            done
          fi

      - name: Lint scripts (flake8)
        run: |
          flake8 scripts --max-line-length=120

      - name: Validate CSV schemas & basic health
        run: |
          python - << 'PY'
import os, sys, csv, pandas as pd

def fail(msg):
    print(f"::error::{msg}")
    sys.exit(1)

def check_csv_exists(path):
    if not os.path.exists(path):
        fail(f"Missing CSV: {path}")
    print(f"Found: {path}")

def read_header(path):
    with open(path, newline='', encoding='utf-8') as f:
        r = csv.reader(f)
        header = next(r, [])
    if not header:
        fail(f"No header row in {path}")
    if len(header) != len(set(header)):
        fail(f"Duplicate column names detected in {path}: {header}")
    if any(h.strip()=="" for h in header):
        fail(f"Empty column name in {path}: {header}")
    print(f"Header OK ({len(header)} cols) for {path}")
    return header

def check_rows_nonempty(path, min_rows=1):
    df = pd.read_csv(path)
    n = len(df)
    print(f"{path}: {n} rows")
    if n < min_rows:
        fail(f"Too few rows in {path}: {n} < {min_rows}")

# Validate topics
topics_path = "data/ajd_topics_extracted.csv"
check_csv_exists(topics_path)
topics_header = read_header(topics_path)
expected_topics_cols = {"topic", "count"}
if not expected_topics_cols.issubset(set(map(str.lower, topics_header))):
    fail(f"{topics_path} must contain columns {expected_topics_cols}, found {topics_header}")
check_rows_nonempty(topics_path, min_rows=1000)

# Validate catalogue
cat_path = "data/ajd_catalogue_raw.csv"
check_csv_exists(cat_path)
cat_header = read_header(cat_path)
required_anycase = [
    "Arabic Name", "English Name", "Series /        One Off / Fillers", "Series Name",
    "Ep.", "Unit By Hour", "Duration", "Country", "Language", "Arabic Synopsis", "English Synopsis"
]
# Allow flexible spacing/case by normalizing
norm = {h.lower().strip(): h for h in cat_header}
missing = [c for c in required_anycase if c.lower().strip() not in norm]
if missing:
    print(f"::warning::Catalogue is missing expected columns (will continue): {missing}")
check_rows_nonempty(cat_path, min_rows=1000)

print("CSV validation completed successfully.")
PY

      - name: Upload merged CSVs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: merged-csvs
          path: |
            data/ajd_topics_extracted.csv
            data/ajd_catalogue_raw.csv

  test:
    name: Tests (matrix)
    runs-on: ubuntu-latest
    needs: lint-and-validate
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Rebuild merged CSVs from chunked parts
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data

          # Merge topics
          if ls data/ajd_topics_extracted.part*.csv 1> /dev/null 2>&1; then
            head -n 1 data/ajd_topics_extracted.part01.csv > data/ajd_topics_extracted.csv
            for f in data/ajd_topics_extracted.part*.csv; do
              if [[ "$f" != "data/ajd_topics_extracted.part01.csv" ]]; then
                tail -n +2 "$f" >> data/ajd_topics_extracted.csv
              fi
            done
          fi

          # Merge catalogue
          if ls data/ajd_catalogue_raw.part*.csv 1> /dev/null 2>&1; then
            head -n 1 data/ajd_catalogue_raw.part01.csv > data/ajd_catalogue_
